{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return 1./(1. + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RBM:\n",
    "    def __init__(self, input_size=784, hidden_size=100):\n",
    "        xavier_range = np.sqrt(6.0/(input_size + hidden_size))\n",
    "#         self.W = np.random.uniform(-xavier_range, xavier_range, (input_size, hidden_size))\n",
    "        self.W = np.random.rand(input_size, hidden_size) * 0.5\n",
    "        self.b = np.zeros((1,hidden_size))\n",
    "        self.a = np.zeros((1,input_size))\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "    def front_propagation(self, input_visible):\n",
    "        activated_hidden = sigma(np.matmul(input_visible, self.W) + self.b)\n",
    "        rand_array = np.random.rand(activated_hidden.shape[0], activated_hidden.shape[1])\n",
    "        h = (activated_hidden > rand_array).astype('int')\n",
    "        return h\n",
    "    \n",
    "    def back_propagation(self, input_hidden):\n",
    "        return sigma(np.matmul(input_hidden, np.transpose(self.W)) + self.a)\n",
    "        \n",
    "    \n",
    "    def train(self, X, learning_rate=0.001, generating=False):\n",
    "        number_of_data = X.shape[0]\n",
    "        h = self.front_propagation(X)\n",
    "        \n",
    "        if generating:\n",
    "            random_seed = np.random.randn(int(number_of_data/4), self.input_size)\n",
    "            temp_1 = self.back_propagation(self.front_propagation(random_seed))\n",
    "            temp_2 = self.back_propagation(self.front_propagation(temp_1))\n",
    "            temp_3 = self.back_propagation(self.front_propagation(temp_2))\n",
    "            temp_4 = self.back_propagation(self.front_propagation(temp_3))\n",
    "            self.X1 = np.concatenate((temp_1, temp_2, temp_3, temp_4), axis=0)\n",
    "        \n",
    "        h1 = self.front_propagation(self.X1)\n",
    "        \n",
    "    \n",
    "        dW = np.matmul(np.transpose(X), h) - np.matmul(np.transpose(self.X1), h1)\n",
    "        db = np.sum(h - h1, axis=0, keepdims=True)\n",
    "        da = np.sum(X - self.X1, axis=0, keepdims=True)\n",
    "        \n",
    "        self.W += learning_rate * dW / number_of_data\n",
    "        self.b += learning_rate * db / number_of_data\n",
    "        self.a += learning_rate * da / number_of_data\n",
    "\n",
    "        error = np.mean(np.sum((X - self.X1) ** 2, axis=1))\n",
    "        self.X1 = self.back_propagation(h1)\n",
    "        \n",
    "        return error\n",
    "        \n",
    "        \n",
    "    def generate_images(self, number_of_images=20, n_step=200):\n",
    "        hidden = np.round(np.random.rand(number_of_images, self.hidden_size))\n",
    "        for i in range(n_step):\n",
    "            visible = self.back_propagation(hidden)\n",
    "            hidden = self.front_propagation(visible)\n",
    "        return visible\n",
    "    \n",
    "    def generate_hidden(self, X, n_step=200):\n",
    "        visible = X\n",
    "        for i in range(n_step):\n",
    "            hidden = self.front_propagation(visible)\n",
    "            visible = self.back_propagation(hidden)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RBM(hidden_size =30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "TRAINING_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 350.311711524\n",
      "Epoch: 2: 114.429178331\n",
      "Epoch: 3: 103.178315692\n",
      "Epoch: 4: 91.0829579889\n",
      "Epoch: 5: 82.1992003559\n",
      "Epoch: 6: 75.2840551598\n",
      "Epoch: 7: 73.7057658782\n",
      "Epoch: 8: 70.8393772321\n",
      "Epoch: 9: 69.0463640413\n",
      "Epoch: 10: 64.8479114732\n",
      "Epoch: 11: 63.4013485728\n",
      "Epoch: 12: 62.58848694\n",
      "Epoch: 13: 59.9430317071\n",
      "Epoch: 14: 59.2990587202\n",
      "Epoch: 15: 61.0670205292\n",
      "Epoch: 16: 58.6353263604\n",
      "Epoch: 17: 60.1990269507\n",
      "Epoch: 18: 62.042835466\n",
      "Epoch: 19: 60.246441129\n",
      "Epoch: 20: 59.1280412389\n",
      "Epoch: 21: 60.6153687627\n",
      "Epoch: 22: 62.0403583696\n",
      "Epoch: 23: 60.4214981031\n",
      "Epoch: 24: 61.2923951547\n",
      "Epoch: 25: 59.8684510043\n",
      "Epoch: 26: 59.9167908286\n",
      "Epoch: 27: 60.0890815993\n",
      "Epoch: 28: 61.094012106\n",
      "Epoch: 29: 61.4278625283\n",
      "Epoch: 30: 61.0541124829\n",
      "Epoch: 31: 63.164065776\n",
      "Epoch: 32: 61.8794658365\n",
      "Epoch: 33: 61.7297856133\n",
      "Epoch: 34: 63.3786313684\n",
      "Epoch: 35: 62.5184443914\n",
      "Epoch: 36: 62.8944869636\n",
      "Epoch: 37: 63.0521557516\n",
      "Epoch: 38: 62.8462312744\n",
      "Epoch: 39: 62.871540866\n",
      "Epoch: 40: 63.4837805973\n",
      "Epoch: 41: 63.7837910958\n",
      "Epoch: 42: 63.4438224134\n",
      "Epoch: 43: 64.394343909\n",
      "Epoch: 44: 63.7940104242\n",
      "Epoch: 45: 63.8530614015\n",
      "Epoch: 46: 63.8809293723\n",
      "Epoch: 47: 64.0051356867\n",
      "Epoch: 48: 64.7210127253\n",
      "Epoch: 49: 64.5392308233\n",
      "Epoch: 50: 64.5494031888\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(TRAINING_EPOCHS):\n",
    "    total_batch = int(mnist.train.num_examples / BATCH_SIZE)\n",
    "    total_error = 0\n",
    "    check = True\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "        total_error += model.train(batch_xs, generating=check)/total_batch\n",
    "        if check:\n",
    "            check = False\n",
    "    print('Epoch: ' + str((epoch + 1)) + ': ' + str(total_error) )\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reshaped_images = np.reshape(model.generate_images(number_of_images=100, n_step=1000), (-1, 28, 28))\n",
    "# for image in reshaped_images:\n",
    "#     plt.imshow(image, cmap='gray')\n",
    "#     plt.show()\n",
    "f, axarr = plt.subplots(10, 10, figsize=(10,10))\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        axarr[i, j].imshow(reshaped_images[i*10 + j])\n",
    "        axarr[i, j].axis('off')\n",
    "        axarr[i, j].set_xticklabels([])\n",
    "        axarr[i, j].set_yticklabels([])\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.1187668099932022, 4.1216199674912994)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_array = []\n",
    "for i in range(total_batch):\n",
    "    images = mnist.train.next_batch(BATCH_SIZE)[0]\n",
    "    hidden = sigma(np.matmul(images, model.W) +  model.b)\n",
    "    hidden = (hidden > 0.5).astype('int')\n",
    "    hidden_array.append(hidden)\n",
    "hidden_array = np.concatenate(hidden_array).tolist()\n",
    "hidden_string_array = []\n",
    "for data in hidden_array:\n",
    "    string = ''\n",
    "    for row in data:\n",
    "        string += str(row)\n",
    "    hidden_string_array.append(string)\n",
    "from collections import Counter\n",
    "counter = Counter(hidden_string_array)\n",
    "p_x = np.array(list(counter.values()))/len(hidden_array)\n",
    "entropy_h = np.sum(-p_x * np.log(p_x))\n",
    "\n",
    "counter_2 = Counter(counter.values())\n",
    "p_x2 = np.array([k*v/len(hidden_array) for k, v in counter_2.items()])\n",
    "entropy_k = np.sum(-p_x2 * np.log(p_x2))\n",
    "entropy_h, entropy_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
